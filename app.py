# app.py - OpenAI version
import gradio as gr
import os
from dotenv import load_dotenv
from scraper import scrape_web_page
from chunker import chunk_text
from embedder import generate_embeddings, save_embeddings, load_embeddings
from retriever import retrieve_relevant_chunks
from llm import generate_answer

# Load environment variables
load_dotenv()

# Global variable to store embeddings
embedding_data = None

def load_and_process_url(url):
    global embedding_data
    
    if not url or not url.strip():
        return "âŒ Please enter a valid URL"
    
    try:
        # Step 1: Scrape the webpage
        print(f"ğŸŒ Scraping: {url}")
        text = scrape_web_page(url)
        
        if text.startswith("Error"):
            return text
        
        if len(text) < 100:
            return "âŒ Not enough content found on this webpage"
        
        # Step 2: Chunk the text
        print("ğŸ“ Chunking text...")
        chunks = chunk_text(text)
        
        if not chunks:
            return "âŒ No valid chunks created from the webpage"
        
        # Step 3: Generate embeddings
        print("ğŸ”¢ Generating embeddings...")
        embedding_data = generate_embeddings(chunks)
        
        # Step 4: Save embeddings
        print("ğŸ’¾ Saving embeddings...")
        save_embeddings(embedding_data)
        
        return f"âœ… Success! Processed {len(chunks)} chunks from {url}\nğŸ“Š Ready to answer questions!"
        
    except Exception as e:
        return f"âŒ Error processing URL: {str(e)}"

def answer_question(question):
    global embedding_data
    
    if not question or not question.strip():
        return "â“ Please enter a question"
    
    if embedding_data is None:
        # Try to load from file
        embedding_data = load_embeddings()
        if embedding_data is None:
            return "âš ï¸ Please process a web page first by entering its URL and clicking 'Process URL'"
    
    try:
        # Step 1: Retrieve relevant chunks
        print(f"ğŸ” Searching for: {question}")
        relevant_chunks = retrieve_relevant_chunks(question, embedding_data)
        
        if not relevant_chunks:
            return "âŒ No relevant information found. Try rephrasing your question."
        
        # Step 2: Generate answer using OpenAI
        print("ğŸ¤– Generating answer with OpenAI...")
        answer = generate_answer(question, relevant_chunks)
        
        return answer
        
    except Exception as e:
        return f"âŒ Error generating answer: {str(e)}"

def clear_data():
    global embedding_data
    embedding_data = None
    try:
        os.remove("embeddings.pkl")
    except:
        pass
    return "ğŸ§¹ Data cleared! You can now process a new webpage."

# Create Gradio interface
with gr.Blocks(
    title="RAG Q&A with OpenAI",
    theme=gr.themes.Soft(),
    css="footer {visibility: hidden}"
) as demo:
    
    gr.Markdown("""
    # ğŸ¤– RAG Q&A Assistant with OpenAI GPT
    
    **HÆ°á»›ng dáº«n sá»­ dá»¥ng:**
    1. ğŸ“ Nháº­p URL cá»§a trang web báº¡n muá»‘n phÃ¢n tÃ­ch
    2. ğŸ”„ Click "Process URL" Ä‘á»ƒ xá»­ lÃ½ trang web
    3. â“ Äáº·t cÃ¢u há»i vá» ná»™i dung trang web
    4. ğŸ¯ Nháº­n cÃ¢u tráº£ lá»i tá»« OpenAI GPT
    
    **Powered by:** OpenAI GPT-3.5-turbo + RAG (Retrieval-Augmented Generation)
    """)
    
    with gr.Row():
        with gr.Column(scale=4):
            url_input = gr.Textbox(
                label="ğŸŒ URL cá»§a trang web",
                placeholder="https://en.wikipedia.org/wiki/Artificial_intelligence",
                info="Nháº­p URL cá»§a trang web báº¡n muá»‘n phÃ¢n tÃ­ch"
            )
        with gr.Column(scale=1):
            process_btn = gr.Button(
                "ğŸ”„ Process URL", 
                variant="primary",
                size="lg"
            )
    
    process_output = gr.Textbox(
        label="ğŸ“Š Tráº¡ng thÃ¡i xá»­ lÃ½",
        lines=3,
        interactive=False,
        info="ThÃ´ng tin vá» quÃ¡ trÃ¬nh xá»­ lÃ½ trang web"
    )
    
    gr.Markdown("---")
    
    with gr.Row():
        with gr.Column(scale=4):
            question_input = gr.Textbox(
                label="â“ CÃ¢u há»i cá»§a báº¡n",
                placeholder="What is artificial intelligence?",
                info="Äáº·t cÃ¢u há»i vá» ná»™i dung trang web Ä‘Ã£ xá»­ lÃ½"
            )
        with gr.Column(scale=1):
            ask_btn = gr.Button(
                "ğŸ” Há»i", 
                variant="secondary",
                size="lg"
            )
    
    answer_output = gr.Textbox(
        label="ğŸ¯ CÃ¢u tráº£ lá»i tá»« OpenAI GPT",
        lines=8,
        interactive=False,
        info="OpenAI GPT sáº½ tráº£ lá»i dá»±a trÃªn ná»™i dung trang web"
    )
    
    with gr.Row():
        clear_btn = gr.Button("ğŸ§¹ Clear Data", variant="stop")
        
    clear_output = gr.Textbox(visible=False)
    
    # Event handlers
    process_btn.click(
        fn=load_and_process_url,
        inputs=[url_input],
        outputs=[process_output]
    )
    
    ask_btn.click(
        fn=answer_question,
        inputs=[question_input],
        outputs=[answer_output]
    )
    
    question_input.submit(
        fn=answer_question,
        inputs=[question_input],
        outputs=[answer_output]
    )
    
    clear_btn.click(
        fn=clear_data,
        outputs=[clear_output]
    )
    
    # Example section
    gr.Markdown("""
    ## ğŸ’¡ VÃ­ dá»¥ URLs Ä‘á»ƒ test:
    - **Wikipedia**: https://en.wikipedia.org/wiki/Machine_learning
    - **Python Docs**: https://docs.python.org/3/tutorial/introduction.html
    - **News**: Báº¥t ká»³ bÃ i bÃ¡o online nÃ o
    
    ## ğŸ’¡ VÃ­ dá»¥ cÃ¢u há»i:
    - "What is the main topic of this article?"
    - "What are the key concepts mentioned?"
    - "Can you summarize the main points?"
    
    ## ğŸ”§ Technical Details:
    - **Embedding**: TF-IDF Vectorization
    - **Retrieval**: Cosine Similarity
    - **LLM**: OpenAI GPT-3.5-turbo
    - **Framework**: Gradio + Python
    """)

if __name__ == "__main__":
    print("ğŸš€ Starting RAG Q&A Assistant with OpenAI...")
    print("ğŸ“‹ Make sure you have set OPENAI_API_KEY in .env file")
    print("ğŸ’° Using OpenAI GPT-3.5-turbo")
    demo.launch(
        share=False,
        server_name="127.0.0.1", 
        server_port=7860,
        show_error=True
    )